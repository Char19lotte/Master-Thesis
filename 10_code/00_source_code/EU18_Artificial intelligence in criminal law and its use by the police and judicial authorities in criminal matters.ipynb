{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Data Collection - European Parliament*\n",
    "## Preparing Raw Data\n",
    "---\n",
    "**Sample Text 18**\n",
    "Title: Artificial intelligence in criminal law and its use by the police and judicial authorities in criminal matters <br>\n",
    "Date: October 4, 2021 - Brussels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import requests\n",
    "from requests_html import HTMLSession\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from urllib import request\n",
    "from __future__ import division\n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "from nltk import FreqDist\n",
    "import os.path \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Process: Trimming debate by inserting the original English or translated English files and tokenizing them.\n",
    "*Note*: Due to time constraint, the process has been optimized.\n",
    "\n",
    "- English parts of the debate will be added manually as a string and then tokenized. \n",
    "\n",
    "- A consistent method of translating and then adding will be applied to all EU Parliament debates:  Non-English parts are copied from the original web pages, inserted in the consistent choice of translation tool, Google Translate (https://translate.google.com/?hl=de&tab=TT), translated to English and pasted in as a string. \n",
    "\n",
    "- Afterwards, the same steps are applied as per usual (tokenizing, standardizing).\n",
    "\n",
    "Because of the changed process, the URL and step of webscraping are technically no longer necessary, will however be included for the purpose of completeness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://www.europarl.europa.eu/doceo/document/CRE-9-2021-10-04-ITM-013_EN.html\"\n",
    "# html = requests.get(url)\n",
    "# raw = BeautifulSoup(html.content, 'html.parser').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Petar Vitanov , rapporteur . – Mr President , the EU regulatory framework needs to catch up with the technical developments . The use of AI has been growing exponentially and this brings the question as to what we , as co-legislators , are doing to safeguard the fundamental rights of European citizens . AI is not a product in itself , but it ’ s a method , it ’ s a tool , and , as such , it needs to be conditioned to the overarching goal of improving the well-being of our citizens . The technology holds great promise if it ’ s developed and used in an ethical and trustworthy manner , but at the same time , it implies considerable risks for fundamental rights , democracy and the rule of law . As co-legislators , we bear enormous responsibility towards European citizens . We need to draw clear red lines for AI—based systems that violate fundamental rights . If we are serious about safeguarding people ’ s safety and well-being , we need to include in the future legislation that can possibly ban or prohibit applications of AI that are incompatible with fundamental rights . Technical progress should never come at the expense of people ’ s fundamental rights . It ’ s not a question of whether the AI systems have the potential to result in racially biased and discriminatory outcomes . We actually know for sure that this is the case . We see the confirmation of this in the data provided by multiple NGOs . We saw it during the Committee on Civil Liberties , Justice and Home Affairs ( LIBE ) mission to Washington last year , and , just a couple of weeks ago , we heard it from the UN High Commissioner for Human Rights . And no , AI is not dangerous only when used by autocratic governments . Where the technology is flawed , it is flawed no matter who uses it and for what purposes . The good intention does not justify the means . There have been numerous cases of people being treated unjustly because of AI , such as being denied social security benefits because of faulty AI tools , or even being arrested because of flawed facial recognition , and somehow I ’ m not surprised that the victims are always the poor , the immigrants , the coloured or the Eastern Europeans . The American Civil Liberties Union demonstrated to the US Congress in May 2019 that the error rate with facial recognition of coloured people is higher , basically leading to de facto discrimination . They described facial recognition technology as unregulated , dangerous , racially biased and often untested . Using facial recognition in public areas may interfere with a person ’ s freedom of opinion and expression simply because of the fact that the protection of group anonymity no longer exists if everyone in the group could potentially be recognised . This could lead to those individuals changing their behaviour , for example by no longer participating in peaceful strikes or demonstrations . Predictive , profiling and risk-assessment AI and ultimate decision—making systems target individuals and profile them as criminals , resulting in serious criminal justice and civil outcomes and punishments before they have carried out the alleged action for which they are being profiled . I always thought that this could only happen in the movies ! In essence , the very purpose of the systems is to undermine the fundamental right to be presumed innocent . Colleagues , I really hope that we can have a serious debate and I ’ m looking forward to it , but I ’ m pretty confident that we will place fundamental rights before technological progress , and even before security , because there can not be any security without freedom . "
     ]
    }
   ],
   "source": [
    "raw1_1 = 'Petar Vitanov, rapporteur. – Mr President, the EU regulatory framework needs to catch up with the technical developments. The use of AI has been growing exponentially and this brings the question as to what we, as co-legislators, are doing to safeguard the fundamental rights of European citizens. AI is not a product in itself, but it’s a method, it’s a tool, and, as such, it needs to be conditioned to the overarching goal of improving the well-being of our citizens. The technology holds great promise if it’s developed and used in an ethical and trustworthy manner, but at the same time, it implies considerable risks for fundamental rights, democracy and the rule of law. As co-legislators, we bear enormous responsibility towards European citizens. We need to draw clear red lines for AI—based systems that violate fundamental rights. If we are serious about safeguarding people’s safety and well-being, we need to include in the future legislation that can possibly ban or prohibit applications of AI that are incompatible with fundamental rights. Technical progress should never come at the expense of people’s fundamental rights. It’s not a question of whether the AI systems have the potential to result in racially biased and discriminatory outcomes. We actually know for sure that this is the case. We see the confirmation of this in the data provided by multiple NGOs. We saw it during the Committee on Civil Liberties, Justice and Home Affairs (LIBE) mission to Washington last year, and, just a couple of weeks ago, we heard it from the UN High Commissioner for Human Rights. And no, AI is not dangerous only when used by autocratic governments. Where the technology is flawed, it is flawed no matter who uses it and for what purposes. The good intention does not justify the means. There have been numerous cases of people being treated unjustly because of AI, such as being denied social security benefits because of faulty AI tools, or even being arrested because of flawed facial recognition, and somehow I’m not surprised that the victims are always the poor, the immigrants, the coloured or the Eastern Europeans. The American Civil Liberties Union demonstrated to the US Congress in May 2019 that the error rate with facial recognition of coloured people is higher, basically leading to de facto discrimination. They described facial recognition technology as unregulated, dangerous, racially biased and often untested. Using facial recognition in public areas may interfere with a person’s freedom of opinion and expression simply because of the fact that the protection of group anonymity no longer exists if everyone in the group could potentially be recognised. This could lead to those individuals changing their behaviour, for example by no longer participating in peaceful strikes or demonstrations. Predictive, profiling and risk-assessment AI and ultimate decision—making systems target individuals and profile them as criminals, resulting in serious criminal justice and civil outcomes and punishments before they have carried out the alleged action for which they are being profiled. I always thought that this could only happen in the movies! In essence, the very purpose of the systems is to undermine the fundamental right to be presumed innocent. Colleagues, I really hope that we can have a serious debate and I’m looking forward to it, but I’m pretty confident that we will place fundamental rights before technological progress, and even before security, because there cannot be any security without freedom.'\n",
    "tokens1_1 = word_tokenize(raw1_1)\n",
    "for word in tokens1_1:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ylva Johansson , Member of the Commission . – Mr President , I would like to thank you for this report and a special thanks to Mr Petar Vitanov for this report . I hear , I know that you are concerned about fundamental rights , and so am I . This summer , gangsters shot down and killed Dutch journalist Peter R. de Vries in cold blood . An attack on a human being . An attack also on our society and our values , on our fundamental rights : the right to life , freedom of expression , freedom of the media . Police caught the suspects within the hour with only a fragment of the getaway car ’ s registration number . Using state-of-the-art camera systems , the police forced the car to a standstill on the motorway . Smart digital technology used in defence of citizens and our fundamental rights . Without this technology , these criminals would have quite simply got away . To protect both our people and their rights digital technology is no longer a “ nice to have ” , but a “ need to have ” or law enforcement . First , because of the massive amounts of data . In one German state last year , the police seized 3 000 terabytes of data in child sexual abuse investigations alone . They estimated it would take one police officer more than 2 000 years to review , and that ’ s assuming an officer working eight hours a day looking at one picture every second . A computer processes these images 10 to 20 times faster at least , 24 hours a day , never gets tired , makes fewer mistakes , doesn ’ t get sick from what they see , does not need therapy . And time is of the essence . In the EncroChat case , Sky ECC and Trojan Shield , the police captured hundreds of millions of messages with criminals plotting drug deals , violent crimes and even murder . Delays can cost lives . Second , criminals increasingly use artificial intelligence to commit deception and fraud , cyber attacks and ransomware attacks . We can not ask the police to bring a knife to a gunfight . We must equip the police with modern tools to fight modern crimes . Third , we need up-to-date information exchange to fight cross-border crime , and I will address this in the upcoming proposals on a police cooperation code and the update of the Prüm framework . I know you are concerned about the rights to privacy and data protection , and I must stress that we must both protect security and respect fundamental rights at the same time , that ’ s essential for the trust of our citizens . We need to demystify technology and explain the strong safeguards that already exist . A balanced approach and strong safeguards should govern the use of technology by law enforcement , anchored in national laws , guarded by data protection authorities , subject to redress mechanisms and parliamentary oversight . There is oversight on European level by , for example , the European Data Protection Supervisor and the Joint Parliamentary Scrutiny Group on Europol . The Court of Justice of the European Union and the European Court of Human Rights have built up a body of case law that is relevant for the use of technology by law enforcement . Procedural rights are already guaranteed : the right to effective remedy , to a fair trial , the rights of defence and the presumption of innocence . I also agree that AI applications must fulfil robust legal and technical requirements , in particular when they are used by public authorities . The legal accountability for the eventual harmful effect of such systems must be clearly assigned . And this is why these issues are addressed in the Commission ’ s proposed AI regulation . We need a European approach to ensure safety and full respect of fundamental rights when artificial intelligence is used . The proposal recognises AI as a strategic tool for law enforcement , to fight terrorism and organised crime . The regulation will facilitate the use of artificial intelligence in a transparent , reliable and secure way , also for law enforcement authorities , by providing clear rules . And I completely agree with you : there is no room for mass surveillance in our society . Our proposal bans mass social scoring and prohibits live biometric identification in public spaces , with a few very well-defined exceptions . But the police must be able to use AI and digital technology for high risk cases with a potential adverse impact on fundamental rights . AI must live up to the highest standards . It must be robust , secure and accurate . The quality of data must be exceptional . Its use must not lead to a discriminatory or racist outcome , and it must be subject to human oversight . When artificial intelligence affects people , people must have the final say . Let me end by saying again that we must protect both security and fundamental rights , and I am convinced that we can , and this is what our citizens want . I hope that you are ready to work together with me to uphold our values and keep our citizens safe . "
     ]
    }
   ],
   "source": [
    "raw1_2 = 'Ylva Johansson, Member of the Commission. – Mr President, I would like to thank you for this report and a special thanks to Mr Petar Vitanov for this report. I hear, I know that you are concerned about fundamental rights, and so am I. This summer, gangsters shot down and killed Dutch journalist Peter R. de Vries in cold blood. An attack on a human being. An attack also on our society and our values, on our fundamental rights: the right to life, freedom of expression, freedom of the media. Police caught the suspects within the hour with only a fragment of the getaway car’s registration number. Using state-of-the-art camera systems, the police forced the car to a standstill on the motorway. Smart digital technology used in defence of citizens and our fundamental rights. Without this technology, these criminals would have quite simply got away. To protect both our people and their rights digital technology is no longer a “nice to have”, but a “need to have” or law enforcement. First, because of the massive amounts of data. In one German state last year, the police seized 3 000 terabytes of data in child sexual abuse investigations alone. They estimated it would take one police officer more than 2 000 years to review, and that’s assuming an officer working eight hours a day looking at one picture every second. A computer processes these images 10 to 20 times faster at least, 24 hours a day, never gets tired, makes fewer mistakes, doesn’t get sick from what they see, does not need therapy. And time is of the essence. In the EncroChat case, Sky ECC and Trojan Shield, the police captured hundreds of millions of messages with criminals plotting drug deals, violent crimes and even murder. Delays can cost lives. Second, criminals increasingly use artificial intelligence to commit deception and fraud, cyber attacks and ransomware attacks. We cannot ask the police to bring a knife to a gunfight. We must equip the police with modern tools to fight modern crimes. Third, we need up-to-date information exchange to fight cross-border crime, and I will address this in the upcoming proposals on a police cooperation code and the update of the Prüm framework. I know you are concerned about the rights to privacy and data protection, and I must stress that we must both protect security and respect fundamental rights at the same time, that’s essential for the trust of our citizens. We need to demystify technology and explain the strong safeguards that already exist. A balanced approach and strong safeguards should govern the use of technology by law enforcement, anchored in national laws, guarded by data protection authorities, subject to redress mechanisms and parliamentary oversight. There is oversight on European level by, for example, the European Data Protection Supervisor and the Joint Parliamentary Scrutiny Group on Europol. The Court of Justice of the European Union and the European Court of Human Rights have built up a body of case law that is relevant for the use of technology by law enforcement. Procedural rights are already guaranteed: the right to effective remedy, to a fair trial, the rights of defence and the presumption of innocence. I also agree that AI applications must fulfil robust legal and technical requirements, in particular when they are used by public authorities. The legal accountability for the eventual harmful effect of such systems must be clearly assigned. And this is why these issues are addressed in the Commission’s proposed AI regulation. We need a European approach to ensure safety and full respect of fundamental rights when artificial intelligence is used. The proposal recognises AI as a strategic tool for law enforcement, to fight terrorism and organised crime. The regulation will facilitate the use of artificial intelligence in a transparent, reliable and secure way, also for law enforcement authorities, by providing clear rules. And I completely agree with you: there is no room for mass surveillance in our society. Our proposal bans mass social scoring and prohibits live biometric identification in public spaces, with a few very well-defined exceptions. But the police must be able to use AI and digital technology for high risk cases with a potential adverse impact on fundamental rights. AI must live up to the highest standards. It must be robust, secure and accurate. The quality of data must be exceptional. Its use must not lead to a discriminatory or racist outcome, and it must be subject to human oversight. When artificial intelligence affects people, people must have the final say. Let me end by saying again that we must protect both security and fundamental rights, and I am convinced that we can, and this is what our citizens want. I hope that you are ready to work together with me to uphold our values and keep our citizens safe.'\n",
    "tokens1_2 = word_tokenize(raw1_2)\n",
    "for word in tokens1_2:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marcel Kolaja , rapporteur for the opinion of the Committee on the Internal Market and Consumer Protection . – Mr President , dear Madam Commissioner , this report calls for a ban on facial recognition systems in public space . That ’ s an important step in fighting against mass surveillance . Unfortunately , amendments have been tabled by a group of Members with the aim of torpedoing the ban and asking for legal means to spy on citizens . I ask you to vote against these amendments . Just last night , thanks to work by 600 journalists worldwide , we learned about tax avoidance and money laundering committed by billionaires and high profile-politicians . For instance , we learned that Czech Prime Minister Andrej Babiš used offshore companies to buy a castle in France . With mass surveillance , journalists can not possibly do their work safely . Two journalists were murdered in the Union just this year . With facial recognition in public space , oligarchs would have even more tools in their hands to persecute and oppress journalists . I speak about oligarchs who systematically work on breaches of the rule of law and on dismantling democracy . The Central and Eastern Europeans used to live under the eye of the Big Brother , and we don ’ t want that to return . "
     ]
    }
   ],
   "source": [
    "raw1_3 = 'Marcel Kolaja, rapporteur for the opinion of the Committee on the Internal Market and Consumer Protection. – Mr President, dear Madam Commissioner, this report calls for a ban on facial recognition systems in public space. That’s an important step in fighting against mass surveillance. Unfortunately, amendments have been tabled by a group of Members with the aim of torpedoing the ban and asking for legal means to spy on citizens. I ask you to vote against these amendments. Just last night, thanks to work by 600 journalists worldwide, we learned about tax avoidance and money laundering committed by billionaires and high profile-politicians. For instance, we learned that Czech Prime Minister Andrej Babiš used offshore companies to buy a castle in France. With mass surveillance, journalists cannot possibly do their work safely. Two journalists were murdered in the Union just this year. With facial recognition in public space, oligarchs would have even more tools in their hands to persecute and oppress journalists. I speak about oligarchs who systematically work on breaches of the rule of law and on dismantling democracy. The Central and Eastern Europeans used to live under the eye of the Big Brother, and we don’t want that to return.'\n",
    "tokens1_3 = word_tokenize(raw1_3)\n",
    "for word in tokens1_3:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angel Djambazki , rapporteur for the opinion of the Committee on Legal Affairs . - Mr. President , colleagues , I also join in thanking my colleague Rapporteur Vitanov for his work on this topic - congratulations colleague ! I agree with you that the report on the need to protect fundamental rights in the use of artificial intelligence in the field of criminal law and the use of the police and the judiciary in criminal matters are useful . As I have already pointed out in the opinion of the Committee on Legal Affairs , artificial intelligence and related technologies would have many benefits in reducing crime , combating trafficking in human beings and sexual exploitation of children , data analysis , and so on . But even when we have to commend them , colleagues , we come to paragraph 9 . He emphasizes that many of the algorithm-based identification technologies currently used make a disproportionate number of errors in identification and classification , thus harming people who are disadvantaged by racism , people belonging to certain ethnic communities , LGBTI and so on and so forth . Colleagues , do any of you assume that artificial intelligence is a racist , misogynist and a person who hates LGBTI ? I have often heard in this Chamber that some people from outside spoke out against this Union and tried to destroy it . No , colleagues , this is not necessary ! Such paragraphs and such claims do much more than all the enemies of this Union . Think about it ! "
     ]
    }
   ],
   "source": [
    "raw1_4 = 'Angel Djambazki, rapporteur for the opinion of the Committee on Legal Affairs. - Mr. President, colleagues, I also join in thanking my colleague Rapporteur Vitanov for his work on this topic - congratulations colleague! I agree with you that the report on the need to protect fundamental rights in the use of artificial intelligence in the field of criminal law and the use of the police and the judiciary in criminal matters are useful. As I have already pointed out in the opinion of the Committee on Legal Affairs, artificial intelligence and related technologies would have many benefits in reducing crime, combating trafficking in human beings and sexual exploitation of children, data analysis, and so on. But even when we have to commend them, colleagues, we come to paragraph 9. He emphasizes that many of the algorithm-based identification technologies currently used make a disproportionate number of errors in identification and classification, thus harming people who are disadvantaged by racism, people belonging to certain ethnic communities, LGBTI and so on and so forth. Colleagues, do any of you assume that artificial intelligence is a racist, misogynist and a person who hates LGBTI? I have often heard in this Chamber that some people from outside spoke out against this Union and tried to destroy it. No, colleagues, this is not necessary! Such paragraphs and such claims do much more than all the enemies of this Union. Think about it!'\n",
    "tokens1_4 = word_tokenize(raw1_4)\n",
    "for word in tokens1_4:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom Vandenkendelaere , on behalf of the PPE Group . – Mr President , AI will shape our future . It will change how we work and live , whether it is in health care , agriculture or , yes , law enforcement . The question isn ’ t whether we like it or not , the question is how Europe will deal with this change . And one thing is clear : AI is here to stay . Already today , criminals are shifting their operations . Whether it is in organised crime , terrorism , child porn , money laundering or human trafficking , it happens online . For me , law enforcement authorities must be able to use the full potential of AI to fight criminals . It will allow them to fight criminality faster , more efficiently and in a more targeted way . And yes , that includes facial recognition in public spaces – on the condition that all fundamental rights are guaranteed and that there is no room for bias . And , colleagues , don ’ t get me wrong . This does not mean that we want to give police forces carte blanche to do whatever they want . It ’ s our duty as policymakers to set up a strong legal framework within which they can safely use AI while guaranteeing the safety of our citizens . It ’ s too easy to argue for moratoria or bans without taking into account the challenges our police officers deal with on the ground . If we really want to be serious about setting up , putting people at the core of trustworthy AI , as we said we would , then it is also about their safety and the benefits AI can bring to better protect ordinary citizens and police officers alike . How do we do that ? It ’ s simple . Let ’ s not get trapped in focusing on certain AI applications and tools , but let us assess each use in its specific context against a set of principles and values , and that is what we should be discussing . Proportionality , necessity , limiting the use in time and place , transparent and strong democratic oversight , and prior legal authorisation where necessary . That ’ s why I think this report falls short of the expectations people have and why my Group presented amendments to it . Digitalisation of our society is inevitable . We can not be blind to this new reality . It is our duty , all together here in this House , to find the right balance between the use of new technologies on the one hand and the protection of our fundamental rights on the other hand . We have to remain vigilant , but we should not throw the baby out with the bathwater . "
     ]
    }
   ],
   "source": [
    "raw1_5 = 'Tom Vandenkendelaere, on behalf of the PPE Group. – Mr President, AI will shape our future. It will change how we work and live, whether it is in health care, agriculture or, yes, law enforcement. The question isn’t whether we like it or not, the question is how Europe will deal with this change. And one thing is clear: AI is here to stay. Already today, criminals are shifting their operations. Whether it is in organised crime, terrorism, child porn, money laundering or human trafficking, it happens online. For me, law enforcement authorities must be able to use the full potential of AI to fight criminals. It will allow them to fight criminality faster, more efficiently and in a more targeted way. And yes, that includes facial recognition in public spaces – on the condition that all fundamental rights are guaranteed and that there is no room for bias. And, colleagues, don’t get me wrong. This does not mean that we want to give police forces carte blanche to do whatever they want. It’s our duty as policymakers to set up a strong legal framework within which they can safely use AI while guaranteeing the safety of our citizens. It’s too easy to argue for moratoria or bans without taking into account the challenges our police officers deal with on the ground. If we really want to be serious about setting up, putting people at the core of trustworthy AI, as we said we would, then it is also about their safety and the benefits AI can bring to better protect ordinary citizens and police officers alike. How do we do that? It’s simple. Let’s not get trapped in focusing on certain AI applications and tools, but let us assess each use in its specific context against a set of principles and values, and that is what we should be discussing. Proportionality, necessity, limiting the use in time and place, transparent and strong democratic oversight, and prior legal authorisation where necessary. That’s why I think this report falls short of the expectations people have and why my Group presented amendments to it. Digitalisation of our society is inevitable. We cannot be blind to this new reality. It is our duty, all together here in this House, to find the right balance between the use of new technologies on the one hand and the protection of our fundamental rights on the other hand. We have to remain vigilant, but we should not throw the baby out with the bathwater.'\n",
    "tokens1_5 = word_tokenize(raw1_5)\n",
    "for word in tokens1_5:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brando Benifei , on behalf of the S & D Group . - ( IT ) Mr President , ladies and gentlemen , as Parliament prepares to examine the proposal for a regulation on artificial intelligence , with this report we are giving a clear message and we are already setting an important point : in Europe , in our opinion , there is no room for mass biometric surveillance and security and the fight against crime can not take place at the expense of the fundamental rights of citizens . In fact , identification by means of biometric data in places accessible to the public risks serious abuses on the right to privacy and on other principles underlying our democratic systems . The European Privacy Guarantor said so : these systems would have a direct negative impact on the exercise of freedom of expression , assembly , association , up to the very freedom of movement . Then let us think about what could happen in places not so attentive to the separation of powers or fundamental freedoms , be they states or cities . The risk of abuse is too great . This is why we believe that the exceptions to Article 5 on prohibited practices of the proposed regulation should be removed . Likewise , predictive techniques for law enforcement carry with them a very serious risk of discrimination , in addition to the lack of evidence on their accuracy , undermining one of the fundamental foundations of our democratic systems , namely the presumption of innocence . No human supervision nor error-free datasets will be sufficient to ensure that decisions of this kind by artificial intelligence systems are made respecting constitutional guarantees and fundamental rights of the Union , even where these decision-making processes are reversible . All the more reason these systems can not be subjected to a mere self-assessment of conformity before being placed on the market , as proposed by the regulation in its first draft under our examination . In fact , a self-assessment exposes to unacceptable risks of errors and violations , which would be discovered only later by the supervisory authorities if they have the means to do so , and this would happen to damage that has now occurred , even irreparable , for the lives of people . In the Union , we already have the most advanced laws in the world on the protection of personal data . For us it is a model , a model that we want to bring to the rest of the world , and we can not afford to move back even one millimeter from this approach when we find ourselves regulating artificial intelligence . In this area too , we must fully protect the rights of citizens . I think this is the way we can act for a Europe that has its own human rights-centered model of artificial intelligence . "
     ]
    }
   ],
   "source": [
    "raw1_6 = 'Brando Benifei, on behalf of the S&D Group. - (IT) Mr President, ladies and gentlemen, as Parliament prepares to examine the proposal for a regulation on artificial intelligence, with this report we are giving a clear message and we are already setting an important point: in Europe, in our opinion, there is no room for mass biometric surveillance and security and the fight against crime cannot take place at the expense of the fundamental rights of citizens. In fact, identification by means of biometric data in places accessible to the public risks serious abuses on the right to privacy and on other principles underlying our democratic systems. The European Privacy Guarantor said so: these systems would have a direct negative impact on the exercise of freedom of expression, assembly, association, up to the very freedom of movement. Then let us think about what could happen in places not so attentive to the separation of powers or fundamental freedoms, be they states or cities. The risk of abuse is too great. This is why we believe that the exceptions to Article 5 on prohibited practices of the proposed regulation should be removed. Likewise, predictive techniques for law enforcement carry with them a very serious risk of discrimination, in addition to the lack of evidence on their accuracy, undermining one of the fundamental foundations of our democratic systems, namely the presumption of innocence. No human supervision nor error-free datasets will be sufficient to ensure that decisions of this kind by artificial intelligence systems are made respecting constitutional guarantees and fundamental rights of the Union, even where these decision-making processes are reversible. All the more reason these systems cannot be subjected to a mere self-assessment of conformity before being placed on the market, as proposed by the regulation in its first draft under our examination. In fact, a self-assessment exposes to unacceptable risks of errors and violations, which would be discovered only later by the supervisory authorities if they have the means to do so, and this would happen to damage that has now occurred, even irreparable, for the lives of people. In the Union, we already have the most advanced laws in the world on the protection of personal data. For us it is a model, a model that we want to bring to the rest of the world, and we cannot afford to move back even one millimeter from this approach when we find ourselves regulating artificial intelligence. In this area too, we must fully protect the rights of citizens. I think this is the way we can act for a Europe that has its own human rights-centered model of artificial intelligence.'\n",
    "tokens1_6 = word_tokenize(raw1_6)\n",
    "for word in tokens1_6:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dragoş Tudorache , on behalf of the Renew Group . – Mr President , dear Commissioner , dear colleagues , the use of artificial intelligence in law enforcement is a political decision , not a technical one . Our duty is to apply our political worldview to determine what are the allowed uses of artificial intelligence and under which conditions . Europe is built on a set of values . They constrain the realm of the possible , dictating what we can not do . And our values also guide our way into the future , dictating what we can and what we should do . What we can not do is to allow the use of technology to lead to a breach of our values . We must only allow AI technologies to be used with straight safeguards and oversight , and we must ensure that human rights are protected throughout . What we also can not do is to allow authorities to use technology for mass surveillance , mass social scoring or any type of government control over citizens . We must be doubly cautious in protecting our values when dealing with law enforcement , as law enforcement is the prerogative of the state . On the other hand , what we can – and should – do is to seek to use AI to reduce the biases and discriminations plaguing our society , including in law enforcement . Technology is a tool . We should invest in it until it is good enough to serve our values . What we also can and should do is ensure law enforcement is competitive and has the best tools at its disposal to fight crime . Fighting crime is also a way to protect our values and should be a top priority for us . We must therefore strengthen the democratic fibre and resilience of our institutions . And tomorrow ’ s challenges will not come from the tools themselves but from our ability or inability to use them in accordance with our values . "
     ]
    }
   ],
   "source": [
    "raw1_7 = 'Dragoş Tudorache, on behalf of the Renew Group. – Mr President, dear Commissioner, dear colleagues, the use of artificial intelligence in law enforcement is a political decision, not a technical one. Our duty is to apply our political worldview to determine what are the allowed uses of artificial intelligence and under which conditions. Europe is built on a set of values. They constrain the realm of the possible, dictating what we cannot do. And our values also guide our way into the future, dictating what we can and what we should do. What we cannot do is to allow the use of technology to lead to a breach of our values. We must only allow AI technologies to be used with straight safeguards and oversight, and we must ensure that human rights are protected throughout. What we also cannot do is to allow authorities to use technology for mass surveillance, mass social scoring or any type of government control over citizens. We must be doubly cautious in protecting our values when dealing with law enforcement, as law enforcement is the prerogative of the state. On the other hand, what we can – and should – do is to seek to use AI to reduce the biases and discriminations plaguing our society, including in law enforcement. Technology is a tool. We should invest in it until it is good enough to serve our values. What we also can and should do is ensure law enforcement is competitive and has the best tools at its disposal to fight crime. Fighting crime is also a way to protect our values and should be a top priority for us. We must therefore strengthen the democratic fibre and resilience of our institutions. And tomorrow’s challenges will not come from the tools themselves but from our ability or inability to use them in accordance with our values.'\n",
    "tokens1_7 = word_tokenize(raw1_7)\n",
    "for word in tokens1_7:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kim Van Sparrentak , on behalf of the Verts/ALE Group . – Mr President , without knowing , we are all being tracked , followed and identified on the streets by facial recognition cameras . This is dangerous , intrusive and disproportionate . Imagine waking up one day with the police barging into your house after AI has flagged you as a suspect . Then it ’ s up to you to prove your innocence . It is you versus the computer . And the myth that a calculation is more ethical than a human is dangerous , especially where decisions impact people ’ s lives . So to my colleagues from the EPP : let ’ s be realistic . AI is not a quick solution to fight crime or terrorism . An AI camera will not detect radicalisation , and automating police work is not a substitute for police funding and community workers . Looking at the US , in New York City and Boston , replacing AI-driven predictive policing with community policing lowered crime rates . And San Francisco and Boston have already banned biometric surveillance in public spaces . So not only is a ban perfectly feasible , we in the EU are far behind in our ethical AI choices . And if we as Parliament are serious about making the EU a leader in ethical AI and fundamental human rights , let ’ s ban biometric surveillance in public spaces . "
     ]
    }
   ],
   "source": [
    "raw1_8 = 'Kim Van Sparrentak, on behalf of the Verts/ALE Group. – Mr President, without knowing, we are all being tracked, followed and identified on the streets by facial recognition cameras. This is dangerous, intrusive and disproportionate. Imagine waking up one day with the police barging into your house after AI has flagged you as a suspect. Then it’s up to you to prove your innocence. It is you versus the computer. And the myth that a calculation is more ethical than a human is dangerous, especially where decisions impact people’s lives. So to my colleagues from the EPP: let’s be realistic. AI is not a quick solution to fight crime or terrorism. An AI camera will not detect radicalisation, and automating police work is not a substitute for police funding and community workers. Looking at the US, in New York City and Boston, replacing AI-driven predictive policing with community policing lowered crime rates. And San Francisco and Boston have already banned biometric surveillance in public spaces. So not only is a ban perfectly feasible, we in the EU are far behind in our ethical AI choices. And if we as Parliament are serious about making the EU a leader in ethical AI and fundamental human rights, let’s ban biometric surveillance in public spaces.'\n",
    "tokens1_8 = word_tokenize(raw1_8)\n",
    "for word in tokens1_8:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jean-Lin Lacapelle , on behalf of the ID group . – Mr President , ladies and gentlemen , artificial intelligence is an admirable tool and has tremendous potential for our peoples and our nations . But as usual , the European Union is spoiling it in the worst way , turning it into an instrument of ideological struggle . Thus , in police and judicial matters , where information technology can allow decisive progress for the safety of our fellow citizens , in particular our children , you limit its use . You claim that artificial intelligence would reproduce and even amplify discrimination , which would force it to forbid certain conclusions and to be as blind as you in the fight against delinquency . You refuse an intelligent system for detecting lies at the borders of the European Union , when 80 % of so-called unaccompanied minors are in fact adults and 70 % of asylum applications are rejected because they are unfounded . You claim that the American George Floyd case , which does not concern us , is proof of alleged racism by the police , and demand national plans to fight against the police rather than against the thugs . We expected this report to talk about artificial intelligence , criminal efficiency , the safety of our fellow citizens and we only have laxity for offenders and ideological lessons for law enforcement and honest citizens . Since Europe does not want to seriously control its borders and fight crime , then the Member States will have to take their destiny into their own hands and decide by election or referendum on the vital questions of security and sovereignty : c is exactly what Marine Le Pen will offer in France in March 2022 . "
     ]
    }
   ],
   "source": [
    "raw1_9 = 'Jean-Lin Lacapelle, on behalf of the ID group. – Mr President, ladies and gentlemen, artificial intelligence is an admirable tool and has tremendous potential for our peoples and our nations. But as usual, the European Union is spoiling it in the worst way, turning it into an instrument of ideological struggle. Thus, in police and judicial matters, where information technology can allow decisive progress for the safety of our fellow citizens, in particular our children, you limit its use. You claim that artificial intelligence would reproduce and even amplify discrimination, which would force it to forbid certain conclusions and to be as blind as you in the fight against delinquency. You refuse an intelligent system for detecting lies at the borders of the European Union, when 80% of so-called unaccompanied minors are in fact adults and 70% of asylum applications are rejected because they are unfounded. You claim that the American George Floyd case, which does not concern us, is proof of alleged racism by the police, and demand national plans to fight against the police rather than against the thugs. We expected this report to talk about artificial intelligence, criminal efficiency, the safety of our fellow citizens and we only have laxity for offenders and ideological lessons for law enforcement and honest citizens . Since Europe does not want to seriously control its borders and fight crime, then the Member States will have to take their destiny into their own hands and decide by election or referendum on the vital questions of security and sovereignty: c is exactly what Marine Le Pen will offer in France in March 2022.'\n",
    "tokens1_9 = word_tokenize(raw1_9)\n",
    "for word in tokens1_9:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eugen Jurzyca , on behalf of the ECR Group . - Mr President , I understand the concern that we would leave algorithms to control decisions that can seriously affect human life . For example , because algorithms can make mistakes . However , I do not agree that we should simply ban the use of artificial intelligence on the basis of such concerns wherever this may have a legal impact on the individual , as proposed in this report . We should have analyzes that compare the functionality and efficiency of human and algorithmic decision-making fairly , and make better decisions about it . At the same time , there are already examples of the successful use of artificial intelligence in criminal matters , which have led to a more efficient and fairer system . For example , the reform of detention in the state of New Jersey . "
     ]
    }
   ],
   "source": [
    "raw1_10 = 'Eugen Jurzyca, on behalf of the ECR Group. - Mr President, I understand the concern that we would leave algorithms to control decisions that can seriously affect human life. For example, because algorithms can make mistakes. However, I do not agree that we should simply ban the use of artificial intelligence on the basis of such concerns wherever this may have a legal impact on the individual, as proposed in this report. We should have analyzes that compare the functionality and efficiency of human and algorithmic decision-making fairly, and make better decisions about it. At the same time, there are already examples of the successful use of artificial intelligence in criminal matters, which have led to a more efficient and fairer system. For example, the reform of detention in the state of New Jersey.'\n",
    "tokens1_10 = word_tokenize(raw1_10)\n",
    "for word in tokens1_10:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cornelia Ernst , on behalf of The Left faction . - Mister President ! I want to be very clear : for our group , biometric face recognition in public spaces is unacceptable . In principle , facial recognition should only be used to a limited extent in strictly regulated cases . The protection of fundamental rights is a measure of every constitutional state . We do not want the comparison of biometric facial features to gradually become a standard procedure in police work . Just what is technically feasible , the simplification of police work , does not justify the automatic use of such a fundamentally invasive technology . And that is why we will also be voting against the amendments of the EPP Group . We have a strong report on the table that clearly states the potential for discrimination through AI , because algorithms can promote social and racist thought patterns . The amendments tabled by the EPP Group thwart that . In the case of biometric facial recognition , it is not just the risk that citizens automatically become objects of suspicion that is relevant . There is also ample evidence of mistakes - of getting innocent people into trouble . Biometric facial recognition , once accepted as a standard , is mass surveillance and a serious invasion of privacy . And that is exactly why any form of surveillance without cause must be prohibited . "
     ]
    }
   ],
   "source": [
    "raw1_11 = 'Cornelia Ernst, on behalf of The Left faction. - Mister President! I want to be very clear: for our group, biometric face recognition in public spaces is unacceptable. In principle, facial recognition should only be used to a limited extent in strictly regulated cases. The protection of fundamental rights is a measure of every constitutional state. We do not want the comparison of biometric facial features to gradually become a standard procedure in police work. Just what is technically feasible, the simplification of police work, does not justify the automatic use of such a fundamentally invasive technology. And that is why we will also be voting against the amendments of the EPP Group. We have a strong report on the table that clearly states the potential for discrimination through AI, because algorithms can promote social and racist thought patterns. The amendments tabled by the EPP Group thwart that. In the case of biometric facial recognition, it is not just the risk that citizens automatically become objects of suspicion that is relevant. There is also ample evidence of mistakes - of getting innocent people into trouble. Biometric facial recognition, once accepted as a standard, is mass surveillance and a serious invasion of privacy. And that is exactly why any form of surveillance without cause must be prohibited.'\n",
    "tokens1_11 = word_tokenize(raw1_11)\n",
    "for word in tokens1_11:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mislav Kolakusic ( NI ) . - Distinguished Chairman , Distinguished Colleagues , Distinguished Citizens , we have witnessed in recent years how some good ideas and some not so good ideas initially turned into a complete disaster . The idea of personal data protection has led us to the fact that today almost every citizen of the European Union has to give every bank to every company he meets almost all his data that he has never had to give before . COVID passports that were introduced to make it easier to travel , today those who are completely healthy and do not own it , are prevented from using health services , from buying at gas stations . Soon they will no longer be allowed to buy food either . Now this idea of biometric monitoring of citizens , although initially only in criminal proceedings , I am convinced that it will apply to monitoring every citizen at all times , and that is unacceptable . "
     ]
    }
   ],
   "source": [
    "raw1_12 = 'Mislav Kolakusic (NI). - Distinguished Chairman, Distinguished Colleagues, Distinguished Citizens, we have witnessed in recent years how some good ideas and some not so good ideas initially turned into a complete disaster. The idea of personal data protection has led us to the fact that today almost every citizen of the European Union has to give every bank to every company he meets almost all his data that he has never had to give before. COVID passports that were introduced to make it easier to travel, today those who are completely healthy and do not own it, are prevented from using health services, from buying at gas stations. Soon they will no longer be allowed to buy food either. Now this idea of biometric monitoring of citizens, although initially only in criminal proceedings, I am convinced that it will apply to monitoring every citizen at all times, and that is unacceptable.'\n",
    "tokens1_12 = word_tokenize(raw1_12)\n",
    "for word in tokens1_12:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeroen Lenaers ( PPE ) . – Mr President , Commissioner , dear colleagues , new technologies often bring enormous opportunities and benefits . But at the same time , we also see often that they provide new avenues for organised crime . It was true for the internet , it is certainly also true for artificial intelligence and machine learning . And at the same time , these technologies can also help us to have huge potential in helping the 1.5 million police officers in the EU to effectively fight crime . They can help in identifying criminals on the run . They can help forecasting criminal activity , and they can help us in finding counterfeit goods and currencies . And we need to look at that potential with an open mind and avoid a situation where criminals profit from AI but law enforcement can not use it to fight them . Yes , there are risks involved , and good safeguards absolutely need to be in place . AI needs to be transparent and trustworthy , and we need to make sure that using AI in the field of law enforcement will never compromise our values . But let ’ s also not be naive . Let ’ s not make the mistake to only focus on the risks and ignore completely the potential . Several colleagues have said it already : AI is here to stay , and its use will only grow in the coming years . And we only have to look at some countries outside the European Union to see what we should not be doing . We need a balanced approach . We need a European approach , because innovation is in our European DNA , as is our ability to create artificial intelligence in a trustworthy , human-centred and valued-based way . Let that be our European trademark in the world , also for law enforcement applications . "
     ]
    }
   ],
   "source": [
    "raw1_13 = 'Jeroen Lenaers (PPE). – Mr President, Commissioner, dear colleagues, new technologies often bring enormous opportunities and benefits. But at the same time, we also see often that they provide new avenues for organised crime. It was true for the internet, it is certainly also true for artificial intelligence and machine learning. And at the same time, these technologies can also help us to have huge potential in helping the 1.5 million police officers in the EU to effectively fight crime. They can help in identifying criminals on the run. They can help forecasting criminal activity, and they can help us in finding counterfeit goods and currencies. And we need to look at that potential with an open mind and avoid a situation where criminals profit from AI but law enforcement cannot use it to fight them. Yes, there are risks involved, and good safeguards absolutely need to be in place. AI needs to be transparent and trustworthy, and we need to make sure that using AI in the field of law enforcement will never compromise our values. But let’s also not be naive. Let’s not make the mistake to only focus on the risks and ignore completely the potential. Several colleagues have said it already: AI is here to stay, and its use will only grow in the coming years. And we only have to look at some countries outside the European Union to see what we should not be doing. We need a balanced approach. We need a European approach, because innovation is in our European DNA, as is our ability to create artificial intelligence in a trustworthy, human-centred and valued-based way. Let that be our European trademark in the world, also for law enforcement applications.'\n",
    "tokens1_13 = word_tokenize(raw1_13)\n",
    "for word in tokens1_13:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iban Garcia Del Blanco ( S & D ) . – Mr President , I would like , first of all , to thank and congratulate the rapporteur for his report , which I believe is absolutely balanced and is in line with what this Parliament has already proposed on several occasions . We have to find , indeed , a balance between the risk for the protection of rights and , of course , the technological development that facilitates us in some way the achievement of objectives of a social nature . But we are , yes , before an issue that directly affects fundamental rights . Several of them are involved in the legal development of this technology , or in the legal field that orders this technology , and , at the same time , social peace is also at stake when we talk about issues that affect security and the established order itself and the rules by which we abide . It is a question that , indeed , some of those realities that science fiction has anticipated in the past - some of them are already a reality today in terms of technological development - do not become a kind of dystopia in our times of those approaches from films such as Minority Report , where the police even anticipate the commission of the crime or the manifested intention because they are capable of foreseeing the possible commission of a crime through technologies such as these ; or , without going any further , that one day we will have those robot judges that in some way would also have delighted some French revolutionaries when they said that `` the mouth that says the law '' , seeking an alleged impartiality in the expression of justice from town . But , at the same time , we also have to avoid obstacles to the development of tools that can effectively help us achieve some of the objectives that can make our societies better ; Of course , in the field of the administration of justice itself , but also as a support tool for our own security forces . We can not ignore those possibilities that artificial intelligence gives and hinder its development . That is why I also want to support this report , which I believe fits perfectly - and this is something I would like to remind some of my colleagues - into the approach that this very Parliament approved almost a year ago - a matter on which I was rapporteur , moreover — , which spoke of ethics applied to artificial intelligence technologies and that I think went in the same direction , trying to avoid scenarios that are not desirable , but also trying at the same time not to get in the way . Ladies and gentlemen , this report can not completely open the barriers and let everyone go their own way and , at the same time , be as intrusive as other colleagues denounce . I think that this is precisely a report that finds the middle ground , that raises very interesting questions . "
     ]
    }
   ],
   "source": [
    "raw1_14 = 'Iban Garcia Del Blanco (S&D). – Mr President, I would like, first of all, to thank and congratulate the rapporteur for his report, which I believe is absolutely balanced and is in line with what this Parliament has already proposed on several occasions. We have to find, indeed, a balance between the risk for the protection of rights and, of course, the technological development that facilitates us in some way the achievement of objectives of a social nature. But we are, yes, before an issue that directly affects fundamental rights. Several of them are involved in the legal development of this technology, or in the legal field that orders this technology, and, at the same time, social peace is also at stake when we talk about issues that affect security and the established order itself and the rules by which we abide. It is a question that, indeed, some of those realities that science fiction has anticipated in the past - some of them are already a reality today in terms of technological development - do not become a kind of dystopia in our times of those approaches from films such as Minority Report, where the police even anticipate the commission of the crime or the manifested intention because they are capable of foreseeing the possible commission of a crime through technologies such as these; or, without going any further, that one day we will have those robot judges that in some way would also have delighted some French revolutionaries when they said that \"the mouth that says the law\", seeking an alleged impartiality in the expression of justice from town. But, at the same time, we also have to avoid obstacles to the development of tools that can effectively help us achieve some of the objectives that can make our societies better; Of course, in the field of the administration of justice itself, but also as a support tool for our own security forces. We cannot ignore those possibilities that artificial intelligence gives and hinder its development. That is why I also want to support this report, which I believe fits perfectly - and this is something I would like to remind some of my colleagues - into the approach that this very Parliament approved almost a year ago - a matter on which I was rapporteur, moreover —, which spoke of ethics applied to artificial intelligence technologies and that I think went in the same direction, trying to avoid scenarios that are not desirable, but also trying at the same time not to get in the way. Ladies and gentlemen, this report cannot completely open the barriers and let everyone go their own way and, at the same time, be as intrusive as other colleagues denounce. I think that this is precisely a report that finds the middle ground, that raises very interesting questions.'\n",
    "tokens1_14 = word_tokenize(raw1_14)\n",
    "for word in tokens1_14:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Svenja Hahn ( Renew ) . - Mister President ! Innovation through artificial intelligence is an almost unbelievable pool for progress . It can also bring relief to the police and judiciary and significantly improve the quality of work . The use of AI in law enforcement , however , often needs the label `` high risk for civil rights '' . And some things need to be prevented altogether . Mass surveillance through automatic facial recognition software in public spaces is a no-go . That is why it is so important that the parliamentary proposal takes a clear position in favor of civil rights and against facial recognition . Human and civil rights are non-negotiable , especially when government agencies adopt new technologies . And I am not a bit surprised that it is again the conservative colleagues in the EPP who are pushing for biometric surveillance . With your amendments , you repeatedly put surveillance dreams – your surveillance dreams – above the protection of our fundamental rights for the umpteenth time . This vote is also a signal for the planned law on artificial intelligence , which importance the European Parliament attaches to our civil rights in the digital future . And I will tell you one thing : I will work every day to ensure that the AI ​​law strengthens our fundamental rights in the EU and does not undermine them . "
     ]
    }
   ],
   "source": [
    "raw1_15 = 'Svenja Hahn (Renew). - Mister President! Innovation through artificial intelligence is an almost unbelievable pool for progress. It can also bring relief to the police and judiciary and significantly improve the quality of work. The use of AI in law enforcement, however, often needs the label \"high risk for civil rights\". And some things need to be prevented altogether. Mass surveillance through automatic facial recognition software in public spaces is a no-go. That is why it is so important that the parliamentary proposal takes a clear position in favor of civil rights and against facial recognition. Human and civil rights are non-negotiable, especially when government agencies adopt new technologies. And I am not a bit surprised that it is again the conservative colleagues in the EPP who are pushing for biometric surveillance. With your amendments, you repeatedly put surveillance dreams – your surveillance dreams – above the protection of our fundamental rights for the umpteenth time. This vote is also a signal for the planned law on artificial intelligence, which importance the European Parliament attaches to our civil rights in the digital future. And I will tell you one thing: I will work every day to ensure that the AI ​​law strengthens our fundamental rights in the EU and does not undermine them.'\n",
    "tokens1_15 = word_tokenize(raw1_15)\n",
    "for word in tokens1_15:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sabrina Pignedoli ( NI ) . - ( IT ) Mr President , ladies and gentlemen , when it comes to artificial intelligence used by law enforcement , there is not only the question of facial recognition , a delicate issue on which a balance must be found . Hackers and criminal groups across Europe are too easily entering the computer systems of public institutions and private companies . For example , they have hit health facilities in Italy , France , Germany and Spain , putting their functioning at risk . Artificial intelligence must become a fundamental tool in the hands of law enforcement to fight cybercrime more effectively . But there is not only the repression of criminal phenomena . Much more needs to be invested in prevention , strengthening the defenses of personal data that can otherwise end up in the data black market . We need to create effective barriers against hackers and use artificial intelligence as a kind of infiltrator , thanks to which law enforcement can block possible attacks before they occur . Prevention is much more effective than cure . "
     ]
    }
   ],
   "source": [
    "raw1_16 = 'Sabrina Pignedoli (NI). - (IT) Mr President, ladies and gentlemen, when it comes to artificial intelligence used by law enforcement, there is not only the question of facial recognition, a delicate issue on which a balance must be found. Hackers and criminal groups across Europe are too easily entering the computer systems of public institutions and private companies. For example, they have hit health facilities in Italy, France, Germany and Spain, putting their functioning at risk. Artificial intelligence must become a fundamental tool in the hands of law enforcement to fight cybercrime more effectively. But there is not only the repression of criminal phenomena. Much more needs to be invested in prevention, strengthening the defenses of personal data that can otherwise end up in the data black market. We need to create effective barriers against hackers and use artificial intelligence as a kind of infiltrator, thanks to which law enforcement can block possible attacks before they occur. Prevention is much more effective than cure.'\n",
    "tokens1_16 = word_tokenize(raw1_16)\n",
    "for word in tokens1_16:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Javier Zarzalejos ( PPE ) . – Mr President , there is no doubt that artificial intelligence is a strategic technology of the 21st century and that this technology also has a place in the field of criminal justice and law enforcement . Today there are forms of crime that can only be combated as effectively as we wish if we make innovative technological tools available to the security forces and the courts . Let us think of money laundering , the financing of terrorism , the proliferation of terrorist content online , the trafficking of human beings by immigration mafias or for purposes of sexual or labor exploitation , or the proliferation of sexual abuse of minors , which require work to identify the victims and the perpetrators and the places where the abuses have been committed , and which test the psychological resistance of those who have to carry out this identification work . It is true that the algorithms have to improve and that their risks require surrounding their use with great safeguards . But I am not in favor of absolute prohibitions , but of guarantees such as those that the amendments presented by my group establish in relation to prior judicial authorization . We have to offer an environment that facilitates the development of artificial intelligence , also in those areas that can be classified as `` high risk '' , with due guarantees . And let me tell you , when talking about examples from other cities or other countries , that it seems to me that the racist biases in these cases are not precisely in the algorithms . "
     ]
    }
   ],
   "source": [
    "raw1_17 = 'Javier Zarzalejos (PPE). – Mr President, there is no doubt that artificial intelligence is a strategic technology of the 21st century and that this technology also has a place in the field of criminal justice and law enforcement. Today there are forms of crime that can only be combated as effectively as we wish if we make innovative technological tools available to the security forces and the courts. Let us think of money laundering, the financing of terrorism, the proliferation of terrorist content online, the trafficking of human beings by immigration mafias or for purposes of sexual or labor exploitation, or the proliferation of sexual abuse of minors, which require work to identify the victims and the perpetrators and the places where the abuses have been committed, and which test the psychological resistance of those who have to carry out this identification work. It is true that the algorithms have to improve and that their risks require surrounding their use with great safeguards. But I am not in favor of absolute prohibitions, but of guarantees such as those that the amendments presented by my group establish in relation to prior judicial authorization. We have to offer an environment that facilitates the development of artificial intelligence, also in those areas that can be classified as \"high risk\", with due guarantees. And let me tell you, when talking about examples from other cities or other countries, that it seems to me that the racist biases in these cases are not precisely in the algorithms.'\n",
    "tokens1_17 = word_tokenize(raw1_17)\n",
    "for word in tokens1_17:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Karen Melchior ( Renew ) . – Mr President , it ’ s not all algorithms or artificial intelligence that are problematic , but predictive profiling and risk assessment artificial intelligence and automated decision—making systems are weapons of mass destruction . They are as dangerous for our democracy as nuclear bombs are for living creatures and life . They will destroy the fundamental rights of each citizen to be equal before the law and in the eye of our authorities . It is not only a question of getting the technology good enough . We must not allow mass surveillance to strip us of our most fundamental rights as citizens , for example the right to unite in demonstrations in public spaces . Madam Commissioner , thank you for underlining the need for modern tools for our judicial authorities . But where is the legal framework that will ensure strict safeguards against misuse and strict democratic control and oversight ? "
     ]
    }
   ],
   "source": [
    "raw1_18 = 'Karen Melchior (Renew). – Mr President, it’s not all algorithms or artificial intelligence that are problematic, but predictive profiling and risk assessment artificial intelligence and automated decision—making systems are weapons of mass destruction. They are as dangerous for our democracy as nuclear bombs are for living creatures and life. They will destroy the fundamental rights of each citizen to be equal before the law and in the eye of our authorities. It is not only a question of getting the technology good enough. We must not allow mass surveillance to strip us of our most fundamental rights as citizens, for example the right to unite in demonstrations in public spaces. Madam Commissioner, thank you for underlining the need for modern tools for our judicial authorities. But where is the legal framework that will ensure strict safeguards against misuse and strict democratic control and oversight?'\n",
    "tokens1_18 = word_tokenize(raw1_18)\n",
    "for word in tokens1_18:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miroslav Radačovský ( NI ) . - Mr President , the report by Mr Vitanov on the use of artificial intelligence in criminal proceedings is good , it is balanced , it is professionally drafted . I am therefore of the opinion that the rather good is that it points to the positives of artificial intelligence in criminal proceedings , and also points to the negatives . In my opinion , as a long-standing judge , I believe that care must be taken in the use of artificial intelligence at the time of court decisions . There , however , it should only exceed the human element , because the decision on guilt and punishment is always individual and no algorithms can apply it to the situation . After all , here in this room too , the President is deciding from time to time , he has to decide , and if that were not the case , there would be artificial intelligence instead of Mr President and artificial intelligence instead of MEPs , because based on algorithms we would know how we have to decide . The potential for the misuse of artificial intelligence in the protection of human rights and freedoms must be avoided , but in principle and in principle , artificial intelligence is beneficial in the fight against crime and must be encouraged and developed . "
     ]
    }
   ],
   "source": [
    "raw1_19 = 'Miroslav Radačovský (NI). - Mr President, the report by Mr Vitanov on the use of artificial intelligence in criminal proceedings is good, it is balanced, it is professionally drafted. I am therefore of the opinion that the rather good is that it points to the positives of artificial intelligence in criminal proceedings, and also points to the negatives. In my opinion, as a long-standing judge, I believe that care must be taken in the use of artificial intelligence at the time of court decisions. There, however, it should only exceed the human element, because the decision on guilt and punishment is always individual and no algorithms can apply it to the situation. After all, here in this room too, the President is deciding from time to time, he has to decide, and if that were not the case, there would be artificial intelligence instead of Mr President and artificial intelligence instead of MEPs, because based on algorithms we would know how we have to decide. The potential for the misuse of artificial intelligence in the protection of human rights and freedoms must be avoided, but in principle and in principle, artificial intelligence is beneficial in the fight against crime and must be encouraged and developed.'\n",
    "tokens1_19 = word_tokenize(raw1_19)\n",
    "for word in tokens1_19:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "President . – Thank you . I hope no one wants to replace me with artificial intelligence as well as the MEPs . "
     ]
    }
   ],
   "source": [
    "raw1_20 = 'President. – Thank you. I hope no one wants to replace me with artificial intelligence as well as the MEPs.'\n",
    "tokens1_20 = word_tokenize(raw1_20)\n",
    "for word in tokens1_20:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tomislav Sokol ( PPE ) . - Honorable Chairman , Commissioners , earlier diagnosis of malignant disease , better traffic management or more rational use of energy are just some of the examples of obvious benefits that the use of artificial intelligence brings . However , if it is not properly regulated , artificial intelligence can threaten the privacy of an individual and lead to various forms of discrimination . Therefore , it is not surprising that as many as 88 percent of citizens believe that it should be managed carefully . The fight against sophisticated , well-funded and equipped terrorist and criminal groups in the 21st century can not be imagined without the use of artificial intelligence . On the other hand , the example of artificial intelligence is particularly sensitive in the field of criminal law because it includes the possibility of geometric recognition and algorithmic decision making . In order to protect citizens from its abuse , but also to become a world leader in smart technologies , the European Union needs a new , comprehensive approach to artificial intelligence . Such an approach should ban the concept of social valuation , which can be used to collect a wide range of data on citizens and their behavior using algorithms . On the other hand , the use of biometric identification systems in public places for law enforcement purposes in accordance with the principle of proportionality should be limited to situations such as searching for a missing child , preventing a specific and imminent terrorist threat and detecting , locating , identifying or investigating against the perpetrator of a serious criminal offense or a suspect for such an offense . We need to strike a balance between using artificial intelligence to catch criminals on the one hand and protecting human rights on the other , but without spreading hysteria and paranoia , which we are unfortunately witnessing here today . "
     ]
    }
   ],
   "source": [
    "raw1_21 = 'Tomislav Sokol (PPE). - Honorable Chairman, Commissioners, earlier diagnosis of malignant disease, better traffic management or more rational use of energy are just some of the examples of obvious benefits that the use of artificial intelligence brings. However, if it is not properly regulated, artificial intelligence can threaten the privacy of an individual and lead to various forms of discrimination. Therefore, it is not surprising that as many as 88 percent of citizens believe that it should be managed carefully. The fight against sophisticated, well-funded and equipped terrorist and criminal groups in the 21st century cannot be imagined without the use of artificial intelligence. On the other hand, the example of artificial intelligence is particularly sensitive in the field of criminal law because it includes the possibility of geometric recognition and algorithmic decision making. In order to protect citizens from its abuse, but also to become a world leader in smart technologies, the European Union needs a new, comprehensive approach to artificial intelligence. Such an approach should ban the concept of social valuation, which can be used to collect a wide range of data on citizens and their behavior using algorithms. On the other hand, the use of biometric identification systems in public places for law enforcement purposes in accordance with the principle of proportionality should be limited to situations such as searching for a missing child, preventing a specific and imminent terrorist threat and detecting, locating, identifying or investigating against the perpetrator of a serious criminal offense or a suspect for such an offense. We need to strike a balance between using artificial intelligence to catch criminals on the one hand and protecting human rights on the other, but without spreading hysteria and paranoia, which we are unfortunately witnessing here today.'\n",
    "tokens1_21 = word_tokenize(raw1_21)\n",
    "for word in tokens1_21:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fabienne Keller ( Renew ) . – Mr President , Commissioner , ladies and gentlemen , the police and judicial fields are not immune to technological developments and among these , artificial intelligence is a new and powerful technology . The use of this tool has proven to be a real asset in the context of certain criminal investigations , the fight against terrorism or border control . Thus , in the terrifying case of the Paris attacks of November 13 , 2015 , it was partly thanks to this technique of artificial intelligence and facial recognition that the investigators were able to identify , locate and arrest the suspected terrorists . However , its use must of course be done under strict control . Indeed , its use must be limited and proportionate , and always be accompanied by human supervision . There must be real work on transparency regarding the technologies used , as well as democratic and above all judicial control over its use , making it possible to avoid any bias and ensure respect for fundamental rights . Dear colleagues , the use of artificial intelligence in criminal cases can be an asset for criminal investigations and for European justice . Let us not deprive ourselves of it , while respecting fundamental freedoms . "
     ]
    }
   ],
   "source": [
    "raw1_22 = 'Fabienne Keller (Renew). – Mr President, Commissioner, ladies and gentlemen, the police and judicial fields are not immune to technological developments and among these, artificial intelligence is a new and powerful technology. The use of this tool has proven to be a real asset in the context of certain criminal investigations, the fight against terrorism or border control. Thus, in the terrifying case of the Paris attacks of November 13, 2015, it was partly thanks to this technique of artificial intelligence and facial recognition that the investigators were able to identify, locate and arrest the suspected terrorists. However, its use must of course be done under strict control. Indeed, its use must be limited and proportionate, and always be accompanied by human supervision. There must be real work on transparency regarding the technologies used, as well as democratic and above all judicial control over its use, making it possible to avoid any bias and ensure respect for fundamental rights. Dear colleagues, the use of artificial intelligence in criminal cases can be an asset for criminal investigations and for European justice. Let us not deprive ourselves of it, while respecting fundamental freedoms.'\n",
    "tokens1_22 = word_tokenize(raw1_22)\n",
    "for word in tokens1_22:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maite Pagazaurtundúa ( Renew ) . – Mr President , thank you , Commissioner Johansson . That Parliament consider the application of artificial intelligence in criminal law and in criminal matters was necessary , even if it is a sensitive issue . We need to find the balance between security and freedom when social or technological circumstances change , and the fact is that they have changed . There are no magic solutions for complex issues , but the police or judges must be able to use technologies that avoid part of the impunity of the most sophisticated cybercrime or terrorism when it has very serious objectives and has enormous resources . Because impunity would also constitute a degradation of the right to justice that society has and , very specifically , the victims . Now , the technology is such , it is so powerful , that the enabling of certain measures , such as facial recognition , should only occur under strict judicial control . It is essential that , in a general sense , the privacy of individuals and even some other guarantees be preserved . I personally have doubts about the moratorium on section 27 , but I have no doubts that we have to continue working on the basis of this report , which will mark our political position , and that the objective must be to have very fine-tuned rules , with large , strong consensus , very majority , of this House . "
     ]
    }
   ],
   "source": [
    "raw1_23 = 'Maite Pagazaurtundúa (Renew). – Mr President, thank you, Commissioner Johansson. That Parliament consider the application of artificial intelligence in criminal law and in criminal matters was necessary, even if it is a sensitive issue. We need to find the balance between security and freedom when social or technological circumstances change, and the fact is that they have changed. There are no magic solutions for complex issues, but the police or judges must be able to use technologies that avoid part of the impunity of the most sophisticated cybercrime or terrorism when it has very serious objectives and has enormous resources. Because impunity would also constitute a degradation of the right to justice that society has and, very specifically, the victims. Now, the technology is such, it is so powerful, that the enabling of certain measures, such as facial recognition, should only occur under strict judicial control. It is essential that, in a general sense, the privacy of individuals and even some other guarantees be preserved. I personally have doubts about the moratorium on section 27, but I have no doubts that we have to continue working on the basis of this report, which will mark our political position, and that the objective must be to have very fine-tuned rules, with large, strong consensus, very majority, of this House.'\n",
    "tokens1_23 = word_tokenize(raw1_23)\n",
    "for word in tokens1_23:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ylva Johansson , Member of the Commission . – Mr President , dear honourable Members , I would like to thank you very much for this debate . Many of you have raised serious concerns on important aspects of artificial intelligence , and I have listened very carefully to your interventions . I will try to answer some of the issues that have been raised in this debate . First , on mass surveillance . I said it already in the beginning , and I completely agree with all of you that have raised this : there ’ s no room for mass surveillance in the EU and in our societies . And we have already strong safeguards in place , and the AI proposal from the Commission will add additional ones . EU data protection rules prohibit , in principle , the processing of biometric data for the purpose of uniquely identifying a natural person , except under very specific conditions . The conditions are clearly laid out in our acquis , the GDPR and the Law Enforcement Directive . This ensures that the use is proportionate and respects the right to data protection and provides for fundamental rights . Further , the AI Act includes the prohibition of real-time remote biometric identification in publicly-accessible places by law enforcement authorities , with very narrow expectations and strong safeguards . The AI Act follows a risk—based approach : the higher the risk , the stricter the rules are . The majority of AI applications are used for purely administrative purposes like translation systems or workflows and do not pose any concerns and require no regulation intervention , while other-use cases , for example the profiling systems used to detect or investigate a crime , or to identify a person remotely , are qualified as high-risk . Many of you have also raised the concerns of facial recognition . Facial recognition is of outstanding importance for law enforcement to identify perpetrators of victims of crime , not just in publicly-accessible spaces but also in the online environment . Such systems are in operation , and they save lives . I have to note that the accuracy of AI technologies is 10 times higher than non-AI technologies , and the overall accuracy of such systems has significantly increased in the last years . In addition , we should not forget that each potential match must be confirmed by the experts before action is taken . Let me be clear : artificial intelligence is not allowed to make decisions to break into a person ’ s home or to arrest a person . Of course not . AI is a necessary tool to help human beings in law enforcement to make the right and timely decision . It ’ s necessary with safeguards : the more intrusive effects , the stronger safeguards are necessary . I ’ m very glad that we all agree that we need a European approach and a common European regulation based on our values . Finally , I would like to say don ’ t put the protection of fundamental rights in contradiction of protecting human beings and protecting societies . It ’ s simply not true that we have to choose . We are capable of doing both . To be able to do so , to find the right balance , we need this kind of open , free democratic debate like we have this evening here in Parliament . Let ’ s continue that debate together to protect both societies , lives and fundamental rights . "
     ]
    }
   ],
   "source": [
    "raw1_24 = 'Ylva Johansson, Member of the Commission. – Mr President, dear honourable Members, I would like to thank you very much for this debate. Many of you have raised serious concerns on important aspects of artificial intelligence, and I have listened very carefully to your interventions. I will try to answer some of the issues that have been raised in this debate. First, on mass surveillance. I said it already in the beginning, and I completely agree with all of you that have raised this: there’s no room for mass surveillance in the EU and in our societies. And we have already strong safeguards in place, and the AI proposal from the Commission will add additional ones. EU data protection rules prohibit, in principle, the processing of biometric data for the purpose of uniquely identifying a natural person, except under very specific conditions. The conditions are clearly laid out in our acquis, the GDPR and the Law Enforcement Directive. This ensures that the use is proportionate and respects the right to data protection and provides for fundamental rights. Further, the AI Act includes the prohibition of real-time remote biometric identification in publicly-accessible places by law enforcement authorities, with very narrow expectations and strong safeguards. The AI Act follows a risk—based approach: the higher the risk, the stricter the rules are. The majority of AI applications are used for purely administrative purposes like translation systems or workflows and do not pose any concerns and require no regulation intervention, while other-use cases, for example the profiling systems used to detect or investigate a crime, or to identify a person remotely, are qualified as high-risk. Many of you have also raised the concerns of facial recognition. Facial recognition is of outstanding importance for law enforcement to identify perpetrators of victims of crime, not just in publicly-accessible spaces but also in the online environment. Such systems are in operation, and they save lives. I have to note that the accuracy of AI technologies is 10 times higher than non-AI technologies, and the overall accuracy of such systems has significantly increased in the last years. In addition, we should not forget that each potential match must be confirmed by the experts before action is taken. Let me be clear: artificial intelligence is not allowed to make decisions to break into a person’s home or to arrest a person. Of course not. AI is a necessary tool to help human beings in law enforcement to make the right and timely decision. It’s necessary with safeguards: the more intrusive effects, the stronger safeguards are necessary. I’m very glad that we all agree that we need a European approach and a common European regulation based on our values. Finally, I would like to say don’t put the protection of fundamental rights in contradiction of protecting human beings and protecting societies. It’s simply not true that we have to choose. We are capable of doing both. To be able to do so, to find the right balance, we need this kind of open, free democratic debate like we have this evening here in Parliament. Let’s continue that debate together to protect both societies, lives and fundamental rights.'\n",
    "tokens1_24 = word_tokenize(raw1_24)\n",
    "for word in tokens1_24:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Petar Vitanov , rapporteur . – Mr President , I am also happy with this debate , because we agree on two things : the benefits of AI in law enforcement on one hand , and , of course , every single colleague here mentioned human rights , fundamental rights . Well , of course , there are divisions . There are definitely two groups . The first one , to which I belong , says that we keep fundamental rights by not letting the use of the unreliable application of AI in order to keep the fundamental rights , and the other group says , and they are convincing us about the conditions of the use of the same unreliable applications in their intentions to protect the unconditional human rights . Of course , it ’ s a political choice . My choice is simple . I urge you not to reject all of the amendments tabled , because they will significantly alter the spirit of this report . But of course , if you prefer the second option , please try to convince that single mother that works 12 hours a day in a poor neighbourhood because she can not afford to live in a better neighbourhood , in a fancy neighbourhood , raising her own children , that her children are potential criminals , or try to convince the poor , the coloured , the immigrants , the foreigners that they are potential criminals only because the AI says so . Is this the world that we want to live in ? Is this the world that we want for our children ? Will we be able to sleep freely at night ? To be honest , I can not . "
     ]
    }
   ],
   "source": [
    "raw1_25 = 'Petar Vitanov, rapporteur. – Mr President, I am also happy with this debate, because we agree on two things: the benefits of AI in law enforcement on one hand, and, of course, every single colleague here mentioned human rights, fundamental rights. Well, of course, there are divisions. There are definitely two groups. The first one, to which I belong, says that we keep fundamental rights by not letting the use of the unreliable application of AI in order to keep the fundamental rights, and the other group says, and they are convincing us about the conditions of the use of the same unreliable applications in their intentions to protect the unconditional human rights. Of course, it’s a political choice. My choice is simple. I urge you not to reject all of the amendments tabled, because they will significantly alter the spirit of this report. But of course, if you prefer the second option, please try to convince that single mother that works 12 hours a day in a poor neighbourhood because she cannot afford to live in a better neighbourhood, in a fancy neighbourhood, raising her own children, that her children are potential criminals, or try to convince the poor, the coloured, the immigrants, the foreigners that they are potential criminals only because the AI says so. Is this the world that we want to live in? Is this the world that we want for our children? Will we be able to sleep freely at night? To be honest, I cannot.'\n",
    "tokens1_25 = word_tokenize(raw1_25)\n",
    "for word in tokens1_25:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Combine all parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokens1_1 + tokens1_2 + tokens1_3 + tokens1_4 + tokens1_5 + tokens1_6 + tokens1_7 + tokens1_8 + tokens1_9 + tokens1_10 + tokens1_11 + tokens1_12 + tokens1_13 + tokens1_14 + tokens1_15 + tokens1_16 + tokens1_17 + tokens1_18 + tokens1_19 + tokens1_20 + tokens1_21 + tokens1_22 + tokens1_23 + tokens1_24 + tokens1_25 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Normalize the words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tokens)\n",
    "eutext18 = [w.lower() for w in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Save Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/Users/charlottekaiser/Documents/uni/Hertie/master_thesis/00_data/20_intermediate_files'\n",
    "file_name = \"EU18_Artificial intelligence in criminal law and its use by the police and judicial authorities in criminal matters.txt\"\n",
    "completeName = os.path.join(save_path, file_name)\n",
    "output = open(completeName, 'w')\n",
    "print(eutext18, file=output)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9869976cf380d12cb70e759e57434a8e82bae01a9f74e734956416b40621c64"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
