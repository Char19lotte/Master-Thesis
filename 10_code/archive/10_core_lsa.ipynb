{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Data Analysis*\n",
    "## Core Analysis - LSA Approach\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/charlottekaiser/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import nltk, re, pprint\n",
    "import json\n",
    "from nltk import word_tokenize\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import os.path \n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import PlaintextCorpusReader \n",
    "from nltk.app import concordance\n",
    "from nltk.corpus import BracketParseCorpusReader\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import altair as alt\n",
    "import tmtoolkit\n",
    "import spacy as spacy\n",
    "import logging, warnings\n",
    "from tmtoolkit.corpus import Corpus\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "nltk.download('omw-1.4')\n",
    "import pickle\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/charlottekaiser/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sample specific stop words that are redundant and have no substantial relevance; also add words that are project-specific stopwords\n",
    "stopwords.add('president')\t\n",
    "stopwords.add('mr')\n",
    "stopwords.add('ms')\n",
    "stopwords.add('commission')\n",
    "stopwords.add('congress')\n",
    "stopwords.add('speaker')\n",
    "stopwords.add('also')\n",
    "stopwords.add('artificial')\n",
    "stopwords.add('intelligence')\n",
    "stopwords.add('digital')\n",
    "stopwords.add('ai')\n",
    "stopwords.add('pro')\n",
    "stopwords.add('tempore')\n",
    "stopwords.add('representative')\n",
    "stopwords.add('thank')\n",
    "stopwords.add('dear')\n",
    "stopwords.add('rapporteur')\n",
    "stopwords.add('lady')\n",
    "stopwords.add('committee')\n",
    "stopwords.add('report')\n",
    "stopwords.add('legislation')\n",
    "stopwords.add('like')\n",
    "stopwords.add('subcommittee')\n",
    "stopwords.add('gentleman')\n",
    "stopwords.add('r')\n",
    "stopwords.add('colleague')\n",
    "stopwords.add('madam')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/charlottekaiser/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Define new function\n",
    "# NLTKâ€™s Wordnet stores meanings of words, synonyms, antonyms, etc. - for ref, see: https://www.nltk.org/_modules/nltk/corpus/reader/wordnet.html \n",
    "# WordNetLemmatizer gets the root, for ref, see: https://www.nltk.org/_modules/nltk/stem/wordnet.html\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "    \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tokenizer for nltk using RegexpTokenizer, to keep tokens that are alphanumeric characters, get rid off punctuation\n",
    "tokenizer = RegexpTokenizer(r'\\w+') \n",
    "# Define a noun tagger \n",
    "is_noun = lambda pos: pos[:2] == 'NN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to preprocess for LDA\n",
    "def prepare_for_lda(text):\n",
    "    text = ''.join(c for c in text if not c.isdigit())\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    tokens = [word for word,pos in tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')] #keep only nouns\n",
    "    tokens = [w.split() for w in tokens if w not in stopwords] # get rid off stopwords\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('.')\n",
    "os.chdir('/Users/charlottekaiser/Documents/uni/Hertie/master_thesis/00_data/40_relevant_debates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "\"EU02_Democratic scrutiny of social media and the protection of fundamental rights.txt\", \n",
    "\"EU03_European strategy for data - Commission evaluation report on the implementation of the General Data Protection Regulation two years after its application.txt\",\n",
    "\"EU11_Digital Europe programme.txt\", \n",
    "\"EU13_Artificial intelligence in education, culture and the audiovisual sector.txt\", \n",
    "\"EU14_Digital future of Europe- digital single market and use of AI for European consumers.txt\",\n",
    "\"EU15_ Promoting gender equality in science, technology, engineering and mathematics - STEM - education and careers.txt\",\n",
    "\"EU18_Artificial intelligence in criminal law and its use by the police and judicial authorities in criminal matters.txt\", \n",
    "\"EU21_The outcome of the EU-US Trade and Technology Council.txt\", \n",
    "\"US02_CONSUMER SAFETY TECHNOLOGY ACT.txt\", \n",
    "\"US04_FEDERAL CAREER OPPORTUNITIES IN COMPUTER SCIENCE WORK ACT.txt\", \n",
    "\"US06_75th ANNIVERSARY OF THE OFFICE OF NAVAL RESEARCH.txt\",\n",
    "\"US09_MSI STEM ACHIEVEMENT ACT.txt\", \n",
    "\"US10_National Defense Authorization Act.txt\", \n",
    "\"US15_FUTURE OF RADAR.txt\", \"US16_DEPARTMENT OF ENERGY SCIENCE FOR THE FUTURE ACT.txt\",\n",
    "\"US18_STATEMENTS ON INTRODUCED BILLS AND JOINT RESOLUTIONS.txt\", \n",
    "\"US20_INTRODUCTION OF THE TRANSATLANTIC TELECOMMUNICATIONS SECURITY ACT.txt\",\n",
    "\"US32_NATIONAL PULSE MEMORIAL.txt\", \n",
    "\"US37_ENDLESS FRONTIER ACT.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_eu02 = open(\"EU02_Democratic scrutiny of social media and the protection of fundamental rights.txt\").read()\n",
    "raw_eu03 = open(\"EU03_European strategy for data - Commission evaluation report on the implementation of the General Data Protection Regulation two years after its application.txt\").read()\n",
    "raw_eu11 = open(\"EU11_Digital Europe programme.txt\").read()\n",
    "raw_eu13 = open(\"EU13_Artificial intelligence in education, culture and the audiovisual sector.txt\").read()\n",
    "raw_eu14 = open(\"EU14_Digital future of Europe- digital single market and use of AI for European consumers.txt\").read()\n",
    "raw_eu15 = open(\"EU15_ Promoting gender equality in science, technology, engineering and mathematics - STEM - education and careers.txt\").read()\n",
    "raw_eu18 = open(\"EU18_Artificial intelligence in criminal law and its use by the police and judicial authorities in criminal matters.txt\").read()\n",
    "raw_eu21 = open(\"EU21_The outcome of the EU-US Trade and Technology Council.txt\").read()\n",
    "raw_us02 = open(\"US02_CONSUMER SAFETY TECHNOLOGY ACT.txt\").read()\n",
    "raw_us04 = open(\"US04_FEDERAL CAREER OPPORTUNITIES IN COMPUTER SCIENCE WORK ACT.txt\").read()\n",
    "raw_us06 = open(\"US06_75th ANNIVERSARY OF THE OFFICE OF NAVAL RESEARCH.txt\").read()\n",
    "raw_us09 = open(\"US09_MSI STEM ACHIEVEMENT ACT.txt\").read()\n",
    "raw_us10 = open(\"US10_National Defense Authorization Act.txt\").read()\n",
    "raw_us15 = open(\"US15_FUTURE OF RADAR.txt\").read()\n",
    "raw_us16 = open(\"US16_DEPARTMENT OF ENERGY SCIENCE FOR THE FUTURE ACT.txt\").read()\n",
    "raw_us18 = open(\"US18_STATEMENTS ON INTRODUCED BILLS AND JOINT RESOLUTIONS.txt\").read()\n",
    "raw_us20 = open(\"US20_INTRODUCTION OF THE TRANSATLANTIC TELECOMMUNICATIONS SECURITY ACT.txt\").read()\n",
    "raw_us32 = open(\"US32_NATIONAL PULSE MEMORIAL.txt\").read()\n",
    "raw_us37 = open(\"US37_ENDLESS FRONTIER ACT.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [raw_eu02, raw_eu03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>debate</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EU02_Democratic scrutiny of social media</td>\n",
       "      <td>['ana', 'paula', 'zacarias', ',', 'president-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EU03_European strategy for data</td>\n",
       "      <td>['henna', 'virkkunen', '(', 'ppe', ')', '.', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     debate  \\\n",
       "0  EU02_Democratic scrutiny of social media   \n",
       "1           EU03_European strategy for data   \n",
       "\n",
       "                                                text  \n",
       "0  ['ana', 'paula', 'zacarias', ',', 'president-i...  \n",
       "1  ['henna', 'virkkunen', '(', 'ppe', ')', '.', '...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign data of lists.  \n",
    "data = {'debate': ['EU02_Democratic scrutiny of social media', \n",
    "'EU03_European strategy for data'], \n",
    "'text': [raw_eu02, raw_eu03]}  \n",
    "  \n",
    "# Create DataFrame  \n",
    "df = pd.DataFrame(data)  \n",
    "  \n",
    "# Print the output.  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text']=df['text'].apply(prepare_for_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['text'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>debate</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EU02_Democratic scrutiny of social media</td>\n",
       "      <td>[[paula], [zacarias], [office], [council], [we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EU03_European strategy for data</td>\n",
       "      <td>[[henna], [virkkunen], [ppe], [year], [ha], [a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     debate  \\\n",
       "0  EU02_Democratic scrutiny of social media   \n",
       "1           EU03_European strategy for data   \n",
       "\n",
       "                                          clean_text  \n",
       "0  [[paula], [zacarias], [office], [council], [we...  \n",
       "1  [[henna], [virkkunen], [ppe], [year], [ha], [a...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9869976cf380d12cb70e759e57434a8e82bae01a9f74e734956416b40621c64"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
